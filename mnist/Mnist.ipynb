{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  ((60000, 28, 28), (60000,))\n",
      "count(x, y):  60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import confluent_kafka as kafka\n",
    "\n",
    "# 1. MNIST Kafka Producer, run separately\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"train: \", (x_train.shape, y_train.shape))\n",
    "\n",
    "producer = kafka.Producer({'bootstrap.servers': 'kafka:29092'})\n",
    "count = 0\n",
    "for (x, y) in zip(x_train, y_train):\n",
    "  \n",
    "  producer.poll(0)\n",
    "  producer.produce('xx', x.tobytes())\n",
    "  producer.produce('yy', y.tobytes())\n",
    "  count += 1\n",
    "\n",
    "print(\"count(x, y): \", count)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(x, y):  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for (x, y) in zip(x_test, y_test):\n",
    "  \n",
    "  producer.poll(0)\n",
    "  producer.produce('xx_test', x.tobytes())\n",
    "  producer.produce('yy_test', y.tobytes())\n",
    "  count += 1\n",
    " \n",
    "print(\"count(x, y): \", count)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 28, 28), (?,)), types: (tf.float32, tf.uint8)>\n",
      "Epoch 1/5\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.6818 - acc: 0.7958\n",
      "Epoch 2/5\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3624 - acc: 0.8875\n",
      "Epoch 3/5\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3061 - acc: 0.9125\n",
      "Epoch 4/5\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3153 - acc: 0.9050\n",
      "Epoch 5/5\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2594 - acc: 0.9217\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io.kafka as kafka_io\n",
    "import datetime\n",
    "\n",
    "# 2. KafkaDataset with map function\n",
    "def func_x(x):\n",
    "  # Decode image to (28, 28)\n",
    "  x = tf.io.decode_raw(x, out_type=tf.uint8)\n",
    "  x = tf.reshape(x, [28, 28])\n",
    "  # Convert to float32 for tf.keras\n",
    "  x = tf.image.convert_image_dtype(x, tf.float32)\n",
    "  return x\n",
    "def func_y(y):\n",
    "  # Decode image to (,)\n",
    "  y = tf.io.decode_raw(y, out_type=tf.uint8)\n",
    "  y = tf.reshape(y, [])\n",
    "  return y\n",
    "train_images = kafka_io.KafkaDataset(['xx:0'], servers=\"kafka:29092\", group='xx', eof=True).map(func_x)\n",
    "train_labels = kafka_io.KafkaDataset(['yy:0'], servers=\"kafka:29092\", group='yy', eof=True).map(func_y)\n",
    "train_kafka = tf.data.Dataset.zip((train_images, train_labels)).batch(1)\n",
    "print(train_kafka)\n",
    "\n",
    "# 3. Keras model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. Add TensorBoard to monitor the model training\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# default: 5 epochs and 12000 steps\n",
    "result = model.fit(train_kafka, epochs=5, steps_per_epoch=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 13ms/step - loss: 0.1520 - acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "test_images = kafka_io.KafkaDataset(['xx:0'], servers=\"kafka:29092\", group='xx', eof=True).map(func_x)\n",
    "test_labels = kafka_io.KafkaDataset(['yy:0'], servers=\"kafka:29092\", group='yy', eof=True).map(func_y)\n",
    "test_kafka = tf.data.Dataset.zip((test_images, test_labels)).batch(1)\n",
    "score = model.evaluate(test_kafka, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
